{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 16S rRNA Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the setup\n",
      "from Bio import SeqIO\n",
      "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "import numpy as np\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load sequences from Fasta file. Header contains NCBI Taxonomy.\n",
      "with open('/Users/austin/Desktop/sample.fa') as handle:\n",
      "    records = list(SeqIO.parse(handle, 'fasta'))\n",
      "    \n",
      "def get_classif(s, level):\n",
      "    ''' hacky regexp to match classification at level '''\n",
      "    try:\n",
      "        return re.search(\"\\[%s\\](\\w*);\" % 1, s).group(1)\n",
      "    except:\n",
      "        return None\n",
      "\n",
      "# Get features & labels\n",
      "dat = [ [get_classif(r.id, 1), str(r.seq)] for r in records ]\n",
      "\n",
      "# Throw out missing labels\n",
      "dat = [ x for x in dat if not x[0] == None ]\n",
      "\n",
      "# Convert to Numpy arrays.\n",
      "labels = np.asarray([x[0] for x in dat])\n",
      "features = np.asarray([x[1] for x in dat])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Setup classifier\n",
      "# (TFIDF) Hashing Vectorizer -> Multinomial Naive Bayes/?\n",
      "classifier = Pipeline([('hash', TfidfVectorizer(analyzer='char',\n",
      "                                                ngram_range=(3, 3))),\n",
      "                       ('classify', KNeighborsClassifier(n_neighbors=len(set(labels))))\n",
      "                       ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cross-validate (3-fold by default)\n",
      "scores = cross_val_score(classifier, features, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '%s +/- %s' % (scores.mean(), scores.std())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.934334334334 +/- 0.00149816111583\n"
       ]
      }
     ],
     "prompt_number": 95
    }
   ],
   "metadata": {}
  }
 ]
}